# Pipeline de Datos de Relaciones con Dagster

## Descripci칩n del Proyecto

Este proyecto implementa un pipeline de datos ETL (Extracci칩n, Transformaci칩n y Carga) utilizando **Dagster** para cumplir con la prueba t칠cnica de Data Engineer Manager.

El objetivo es procesar una matriz de relaciones entre personas, proporcionada en un archivo Excel, y cargarla en una base de datos MySQL. El pipeline est치 dise침ado para ser robusto y automatizado, ejecut치ndose diariamente para reflejar las actualizaciones enviadas por el equipo de datos.

El proceso se puede resumir en los siguientes pasos:

1. **Extracci칩n:** Lee los datos de dos hojas de un archivo `relaciones.xlsx`: una matriz de adyacencia y una lista de actores.
2. **Transformaci칩n:** Limpia y procesa los datos para convertirlos en tablas relacionales normalizadas. La l칩gica est치 dise침ada para ser resiliente a inconsistencias comunes en archivos Excel, como filas vac칤as, datos dispersos o no contiguos.
3. **Carga:** Carga los datos limpios en tablas (`user_relationships`, `actors`) en una base de datos MySQL. Adicionalmente, crea una vista (`v_actor_relationships`) para facilitar la consulta de los datos de forma legible.
4. **Orquestaci칩n:** Todo el proceso est치 orquestado por Dagster, con una programaci칩n para ejecutarse cada 24 horas.

## Arquitectura y Tecnolog칤as Utilizadas

- **Orquestador de Pipeline:** Dagster
- **Contenerizaci칩n:** Docker & Docker Compose
- **Base de Datos:** MySQL 8.0
- **Lenguaje de Programaci칩n:** Python 3.9
- **Librer칤as Clave:** Pandas, NumPy, SQLAlchemy

## 游 Setup y Ejecuci칩n

Sigue estos pasos para configurar y ejecutar el pipeline de ETL en tu entorno local.

### Prerrequisitos

- Docker y Docker Compose instalados.

### 1. Configuraci칩n del Entorno

Este proyecto utiliza variables de entorno para gestionar las credenciales de la base de datos.

#### Crear archivo de entorno

Copia el archivo de ejemplo `.env.example` a un nuevo archivo llamado `.env`. Este archivo `.env` ser치 utilizado por Docker Compose pero est치 excluido de Git por seguridad.

```bash
# En Linux o macOS
cp .env.example .env

# En Windows (Command Prompt o PowerShell)
copy .env.example .env
```

#### Editar el archivo `.env`

Abre tu nuevo archivo `.env` y reemplaza los valores de ejemplo con tus propias credenciales para la base de datos.

### 2. Levantar los Servicios

Una vez que tu archivo `.env` est칠 configurado, puedes levantar todos los servicios usando Docker Compose.

```bash
# Este comando construir치 las im치genes y levantar치 los contenedores.
docker-compose up --build
```

### 3. Ejecutar el Pipeline en Dagster

Tras una ejecuci칩n exitosa de `docker-compose up`, sigue estos pasos en la interfaz de Dagster:

#### Acceder a la Interfaz Web

Abre tu navegador y ve a [http://localhost:3000](http://localhost:3000). Ver치s el grafo de assets que define las dependencias del pipeline.

![Vista del Lineage](./docs/images/01-view-lineage.png)

#### Materializar los Datos

Para ejecutar el pipeline completo, haz clic en el bot칩n "View lineage" en la esquina superior derecha. Esto te llevar치 a ver el global asset lineage, despu칠s da click en "Materialize all" en la esquina superior derecha.

![Global Asset Lineage](./docs/images/02-global-asset-lineage.png)

#### Monitorear la Ejecuci칩n

Da click en la pesta침a "Runs", esquina superior izquierda, donde podr치s ver el progreso de la ejecuci칩n en tiempo real. Cada asset se ejecutar치 como un paso, y se volver치 verde al completarse con 칠xito.

![Run en Progreso](./docs/images/03-run-in-progress.png)

#### Verificar el Resultado en la Base de Datos

Una vez que la ejecuci칩n haya finalizado, los datos estar치n en tu base de datos MySQL. Puedes conectarte con tu cliente SQL preferido (DBeaver, MySQL Workbench, etc.) y ejecutar una consulta para verificar los resultados. La vista `v_actor_relationships` es ideal para una revisi칩n legible.

```sql
SELECT * FROM relationships_db.v_actor_relationships
ORDER BY person_a_id, person_b_id;
```

![Resultado de Query SQL](./docs/images/04-sql-query-result.png)

## 游댌 Notas de Dise침o y Decisiones Importantes

Para asegurar la robustez del pipeline, se tomaron varias decisiones clave:

### 1. El Desaf칤o de Usar Excel como Fuente de Datos

Los archivos Excel son una fuente de datos notoriamente fr치gil. Algunos de los problemas identificados y mitigados fueron:

- **Datos Dispersos:** El pipeline est치 dise침ado para manejar escenarios donde se a침aden datos de forma no contigua (ej., se a침ade informaci칩n para el ID 25 sin tener datos para los IDs 19-24).
- **Filas/Columnas Vac칤as:** La l칩gica de lectura ignora las filas y columnas completamente en blanco, que a menudo act칰an como terminadores prematuros en librer칤as como Pandas.
- **Inconsistencias de Tipo:** Todo el bloque de datos de la matriz se convierte a un tipo num칠rico uniforme para evitar errores de comparaci칩n (1.0 vs 1 vs "1").

### 2. Decisi칩n de Usar IDs Num칠ricos como Clave Principal

Durante el desarrollo, se identific칩 una inconsistencia en los c칩digos de letra utilizados como identificadores en la matriz. Para evitar esta fragilidad, se decidi칩 utilizar los IDs num칠ricos como la 칰nica fuente de verdad para las relaciones. El pipeline usa la primera columna num칠rica de la matriz como el 칤ndice maestro, asegurando que la matriz de adyacencia sea siempre cuadrada y coherente.

### 3. Estructura de la Base de Datos

El pipeline crea dos tablas principales y una vista:

- **`actors`:** Almacena la relaci칩n entre el ID num칠rico, el c칩digo de letra y el nombre del actor.
- **`user_relationships`:** Almacena los pares de IDs que tienen una relaci칩n.
- **`v_actor_relationships`:** Una vista que une las dos tablas anteriores para presentar una visi칩n legible de las relaciones.

## 游 Punto Opcional y Mejoras Futuras

- **Validaci칩n de Datos:** Se explor칩 la implementaci칩n de Dagster Asset Checks para validar la calidad de los datos (ej., unicidad de IDs). Aunque se encontr칩 un problema de versionado con el entorno Docker local, esta sigue siendo la mejora m치s recomendada para un entorno de producci칩n.
- **Sensor de Archivos:** Se podr칤a implementar un Sensor en Dagster que detecte autom치ticamente la actualizaci칩n del archivo `relaciones.xlsx` y lance el pipeline, en lugar de depender 칰nicamente de una ejecuci칩n programada.